{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from gzip import open as gopen\n",
    "import subprocess\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# seed the rng\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each simulation directory to generate corrected transmission networks, sample data and time trees\n",
    "for i in range(1,1101):\n",
    "    # generate latent period\n",
    "    latent_period = np.random.exponential(2.9/365) #expected value is 2.9/365 days\n",
    "    # set up file paths for transmission network\n",
    "    old_tn_path = f'simulations/{i:04d}/transmission_network.subsampled.txt.gz'\n",
    "    new_tn_path = f'simulations/{i:04d}/transmission_network.subsampled.corrected.txt'\n",
    "    # open files and write out the corrected data\n",
    "    with gopen(old_tn_path, 'rt') as old_tn, open(new_tn_path, 'w') as new_tn:\n",
    "        for line in old_tn:\n",
    "            u, v, t = line.strip().split('\\t')\n",
    "            new_tn.write(f'{u}\\t{v}\\t{float(t) + latent_period:.6f}\\n')\n",
    "    # set up file paths for sample times\n",
    "    old_samples_path = f'simulations/{i:04d}/subsample_times.txt.gz'\n",
    "    new_samples_path = f'simulations/{i:04d}/subsample_times.corrected.txt'\n",
    "    # open files and write out the corrected data\n",
    "    with gopen(old_samples_path, 'rt') as old_samples, open(new_samples_path, 'w') as new_samples:\n",
    "        for line in old_samples:\n",
    "            u, t = line.strip().split('\\t')\n",
    "            new_samples.write(f'{u}\\t{float(t) + latent_period}\\n')\n",
    "    # setup and run CoaTRan to generate corrected time trees\n",
    "    command = ['coatran_constant', new_tn_path, new_samples_path, '1']\n",
    "    env = os.environ.copy()\n",
    "    coatran_rng_seed = np.random.randint(low=0, high=2**31) # ensure it is reproducible\n",
    "    env[\"COATRAN_RNG_SEED\"] = str(coatran_rng_seed)\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error executing CoaTran for simulation {i}: {result.stderr.decode()}\")\n",
    "        print(command)\n",
    "    else:\n",
    "        tree_path = f'simulations/{i:04d}/tree.time.subsampled.corrected.nwk'\n",
    "        with open(tree_path, 'w') as file_handle:\n",
    "            file_handle.write(result.stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output folder for each of 1000 resamples\n",
    "# each with subfolders for CC and AB clade analysisiresults\n",
    "if os.path.exists('resamples'):\n",
    "    # Remove the directory and its contents\n",
    "    shutil.rmtree('resamples')\n",
    "os.makedirs('resamples')\n",
    "for i in range(1000):\n",
    "    # create path for this resample\n",
    "    os.makedirs(f'resamples/{i}')\n",
    "    # create subdirectory with clade analysis results subdirectories\n",
    "    os.makedirs(f'resamples/{i}/clade_analyses_CC')\n",
    "    os.makedirs(f'resamples/{i}/clade_analyses_AB')\n",
    "    os.makedirs(f'resamples/{i}/clade_analyses_CC_exact')\n",
    "    os.makedirs(f'resamples/{i}/clade_analyses_AB_exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to call stableCoalescence_cladeAnalysis.py\n",
    "# to resample one simulation 1000 times\n",
    "def resample_simulation(i, seed):\n",
    "    command = [\n",
    "        \"python3\",\n",
    "        \"stableCoalescence_cladeAnalysis.py\",\n",
    "        \"-tn\", f'simulations/{i:04d}/transmission_network.subsampled.corrected.txt',\n",
    "        \"-tt\", f'simulations/{i:04d}/tree.time.subsampled.corrected.nwk',\n",
    "        \"-g\", f'simulations/{i:04d}/GEMF_files/output.txt.gz',\n",
    "        \"-s\", \"0.00092\",\n",
    "        \"-m\", \"1\",\n",
    "        \"-id\", f'{i:04d}',\n",
    "        \"-seed\", str(seed)\n",
    "    ]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample each of the 1100 simulations with a deterministic seed\n",
    "seeds = np.random.randint(0, 2**31, size=1100)\n",
    "with ProcessPoolExecutor(max_workers=24) as executor:\n",
    "    executor.map(resample_simulation, range(1, 1101), seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primary analysis (3.47-day doubling time, 15% ascertainment rate) tree sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clade_results(dir):\n",
    "    clade_analyses_d = dict()\n",
    "    for path in sorted(os.listdir(dir)): # pool all clade analyses together\n",
    "        clade_analysis_path = dir + path\n",
    "        key = int(path.split('_')[0])\n",
    "        clade_analyses_d[key] = {'clade_sizes': [], 'subclade_sizes': []}\n",
    "        for line in open(clade_analysis_path):\n",
    "            l = line.strip().strip(']').split('[')\n",
    "            clade_size = int(l[0].strip()) # make each clade size (including single leaves) an integer\n",
    "            subclade_sizes = [int(x) for x in l[1].strip().replace(' ', '').split(',')] # put each subclade size (including single leaves) into a list\n",
    "            clade_analyses_d[key]['clade_sizes'].append(clade_size)\n",
    "            clade_analyses_d[key]['subclade_sizes'].append(subclade_sizes)\n",
    "    return clade_analyses_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_root_mutations(dir):\n",
    "    root_mutations_d = dict()\n",
    "    for path in sorted([f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))]): \n",
    "        root_mutations_path = dir + path\n",
    "        key = int(path.split('_')[0])\n",
    "        with open(root_mutations_path) as file:\n",
    "            root_mutations_d[key] = int(file.readline().strip())\n",
    "    return root_mutations_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than 787 taxa: 0.017273\n",
      "More than 1000 taxa: 0.980909\n",
      "More than 5000 taxa: 0.953636\n"
     ]
    }
   ],
   "source": [
    "clade_analyses_CC_dir = './resamples/0/clade_analyses_CC/'\n",
    "clade_analyses_AB_dir = './resamples/0/clade_analyses_AB/'\n",
    "\n",
    "clade_analyses_CC_d = read_clade_results(clade_analyses_CC_dir)\n",
    "\n",
    "print('Less than 787 taxa: %f' % (sum([sum(clade_analyses_CC_d[x]['clade_sizes']) < 787 for x in clade_analyses_CC_d])/1100)) \n",
    "print('More than 1000 taxa: %f' % (sum([sum(clade_analyses_CC_d[x]['clade_sizes']) > 1000 for x in clade_analyses_CC_d])/1100))\n",
    "print('More than 5000 taxa: %f' % (sum([sum(clade_analyses_CC_d[x]['clade_sizes']) > 5000 for x in clade_analyses_CC_d])/1100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree shapes and bayes factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained_results = np.array([1.68,80.85, 10.32, 0.92])/100 # linB, linA, C/C, T/T\n",
    "recCA_results = np.array([77.28, 8.18, 10.49, 3.71])/100 # linB, linA, C/C, T/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bf(asr_results, simulation_results):\n",
    "    # Let t_p be a polytomy, t_1C be one clade, and t_2c be two clades. Note that t_p includes t_1c. t_p equals all topologies with a basal polytomy (Fig. 2a). \n",
    "    # trees are in the order\n",
    "    # (t_p, t_1C, t_2C, (t_p,(t_p,t_1C,t_2C)), (t_1C,(t_p,t_1C,t_2C)), (t_2c,(t_p,t_1C,t_2C)))\n",
    "    compatibility_matrix = np.array([np.array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), # S_A\n",
    "                                     np.array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), # S_B\n",
    "                                     np.array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]), # S_CC\n",
    "                                     np.array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])] # S_TT\n",
    "                                    )\n",
    "                                    \n",
    "    # A matrix of conditional probabilities\n",
    "    # Each row stores the vector Pr(S_MRCA | \\btau)\n",
    "    pr_s_mrca_given_tree = np.array([x/sum(x) if sum(x) > 0 else x for x in compatibility_matrix.T]) # if tree not associated with any haplotype, just keep the row as all 0s\n",
    "    \n",
    "    # Order: S_A, S_B, S_{C/C}, S_{T/T}\n",
    "    pr_s_mrca_given_data = np.array(asr_results)/sum(asr_results)\n",
    "    unnormalized_pr_data_given_s_mrca = pr_s_mrca_given_data.copy()\n",
    "    \n",
    "    # FAVITES simulation information\n",
    "    # the 3 trees are in the order (t_p, t_1C, t_2C)\n",
    "    pr_3_topos = np.array(simulation_results)\n",
    "    pr_trees_given_I1 = np.concatenate([pr_3_topos, np.array([0]*9)])\n",
    "    pr_trees_given_I2 = np.concatenate([np.array([0]*3), np.array([simulation_results[0]]), np.array([0]*8)])\n",
    "    \n",
    "    # Equal prior probability of 1 or 2 intros\n",
    "    pr_I1 = 0.5\n",
    "    pr_I2 = 0.5\n",
    "    \n",
    "    pr_s_mrca_and_I1 = np.dot([np.dot(pr_s_mrca_given_tree.T[i], pr_trees_given_I1) for i in range(0,4)], pr_I1) # dot product of P(haplotype|tree) (column) and P(trees|I_n), scaled by P(I_n)\n",
    "    pr_s_mrca_and_I2 = np.dot([np.dot(pr_s_mrca_given_tree.T[i], pr_trees_given_I2) for i in range(0,4)], pr_I2)\n",
    "\n",
    "    posterior_odds = np.dot(unnormalized_pr_data_given_s_mrca, pr_s_mrca_and_I2) / np.dot(unnormalized_pr_data_given_s_mrca, pr_s_mrca_and_I1)\n",
    "    prior_odds = pr_I2/pr_I1\n",
    "    BF = posterior_odds/prior_odds\n",
    "\n",
    "    return(BF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sizes(run_1,run_2,interval):\n",
    "    # read samples into seperate sets for each run\n",
    "    sample_dict = {run_1: set(), run_2: set()}\n",
    "    # read transmissions into one list for both runs\n",
    "    transmission_list = []\n",
    "    for run in [run_1, run_2]:\n",
    "        with open(f'simulations/{run:04d}/subsample_times.corrected.txt', 'r') as file:\n",
    "            for line in file:\n",
    "                u, t = line.strip().split('\\t')\n",
    "                sample_dict[run].add(u)\n",
    "        with open(f'simulations/{run:04d}/transmission_network.subsampled.corrected.txt', 'r') as file:\n",
    "            for line in file:\n",
    "                u,v,t = line.strip().split()\n",
    "                if u != v:\n",
    "                    if run == run_2:\n",
    "                        t = float(t) + interval\n",
    "                    else:\n",
    "                        t = float(t)\n",
    "                    transmission_list.append((v,t,run))\n",
    "    # sort the transmissions\n",
    "    transmission_list = sorted(transmission_list, key=lambda x: x[1])\n",
    "    # start sample counts from -1 to compensate for the primary sample\n",
    "    n_valid_samples = {run_1: -1, run_2: -1}\n",
    "    # got through the transmissions from earliest to latest\n",
    "    for event_no, transmission in enumerate(transmission_list):\n",
    "        # check if the transmission is amongst the samples of its run\n",
    "        if transmission[0] in sample_dict[transmission[2]]:\n",
    "            # increment the count for that run\n",
    "            n_valid_samples[transmission[2]] += 1\n",
    "        # stop after the first 50,000\n",
    "        if event_no == 50000:\n",
    "            break\n",
    "    # compare the numbers of sampled transmissions to the relative size condition \n",
    "    if 0.3 <= n_valid_samples[run_1]/(n_valid_samples[run_1] + n_valid_samples[run_2]) <= 0.7:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clade_analysis_updated(clade_analyses_CC_dir, clade_analyses_AB_dir, clade_analyses_CC_exact_dir, clade_analyses_AB_exact_dir, root_mutations_dir, label, expected_coalescence_range, expected_introduction_range, seed, min_polytomy_size=100, _print_=False):\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    clade_analyses_CC_d = read_clade_results(clade_analyses_CC_dir) \n",
    "    clade_analyses_AB_d = read_clade_results(clade_analyses_AB_dir)\n",
    "    clade_analyses_CC_exact_d = read_clade_results(clade_analyses_CC_exact_dir)\n",
    "    clade_analyses_AB_exact_d = read_clade_results(clade_analyses_AB_exact_dir)\n",
    "    root_mutations_d = read_root_mutations(root_mutations_dir)\n",
    "    \n",
    "    # C/C analysis\n",
    "    cc_count = 0 # how often are there only two 1-mutation clades, each constituting more than 30% of taxa AND with a polytomy at the base of each clade, and no other descendants from the root?\n",
    "    cc_exact_count = 0\n",
    "    for run in clade_analyses_CC_d:\n",
    "        clade_sizes = clade_analyses_CC_d[run]['clade_sizes']\n",
    "        if len(clade_sizes) == 2: # make sure there are only two clades\n",
    "            if min(clade_sizes) > (sum(clade_sizes)*0.30): # make sure each clade is >30%\n",
    "                subclade_sizes = clade_analyses_CC_d[run]['subclade_sizes']\n",
    "                if len(subclade_sizes[0]) >= min_polytomy_size and len(subclade_sizes[1]) >= min_polytomy_size: # each clade must have a polytomy at the base\n",
    "                    cc_count += 1\n",
    "                    if len(clade_analyses_CC_exact_d[run]['clade_sizes']) == 2:\n",
    "                        cc_exact_count += 1\n",
    "    \n",
    "    # A/B analysis\n",
    "    ab_count = 0 # interested in 2 mutations clade that are at least 30% of all taxa + has a basal polytomy + polytomy at 2 mutation clade\n",
    "    ab_exact_count = 0\n",
    "    lower_constraint = 0.3 # the 2-mutation clade must be at least 30% of all taxa\n",
    "    upper_constraint = 0.7 # the 2-mutation clade must be at most 70% of all taxa\n",
    "\n",
    "    for run in clade_analyses_AB_d:\n",
    "        num_leaves = sum(clade_analyses_CC_d[run]['clade_sizes'])\n",
    "        base_polytomy_size = len(clade_analyses_CC_d[run]['clade_sizes']) # check how many lineages descend from the root\n",
    "        clade_sizes = clade_analyses_AB_d[run]['clade_sizes'] \n",
    "        subclade_sizes = clade_analyses_AB_d[run]['subclade_sizes']\n",
    "        clade_sizes_exact = clade_analyses_AB_exact_d[run]['clade_sizes'] \n",
    "        subclade_sizes_exact = clade_analyses_AB_exact_d[run]['subclade_sizes']\n",
    "        if not clade_sizes: # no 2 mutation clades\n",
    "            continue\n",
    "        if base_polytomy_size >= min_polytomy_size: # basal polytomy\n",
    "            for index, clade_size in enumerate(clade_sizes): # loop through all 2 mutation clades\n",
    "                if lower_constraint*num_leaves <= clade_size <= upper_constraint*num_leaves: # clade match size restrictions\n",
    "                    if len(subclade_sizes[index]) >= min_polytomy_size: # polytomy at 2 mutation clade\n",
    "                        ab_count += 1 # if all conditions are met, add 1 to the count\n",
    "                        break # if one 2 mutation clade meets the conditions, break out of the loop and move on to the next run\n",
    "            for index, clade_size in enumerate(clade_sizes_exact): # loop through all 2 mutation clades\n",
    "                if lower_constraint*num_leaves <= clade_size <= upper_constraint*num_leaves: # clade match size restrictions\n",
    "                    if len(subclade_sizes_exact[index]) >= min_polytomy_size: # polytomy at 2 mutation clade\n",
    "                        ab_exact_count += 1 # if all conditions are met, add 1 to the count\n",
    "                        break # if one 2 mutation clade meets the conditions, break out of the loop and move on to the next run\n",
    "\n",
    "    CC_two_intros = []\n",
    "    AB_two_intros = []\n",
    "    CC_exact_two_intros = []\n",
    "    AB_exact_two_intros = []\n",
    "    for expected_coalescence in expected_coalescence_range:\n",
    "        CC_two_intros_v = []\n",
    "        AB_two_intros_v = []\n",
    "        CC_exact_two_intros_v = []\n",
    "        AB_exact_two_intros_v = []\n",
    "        for expected_introduction in expected_introduction_range:\n",
    "            AB = 0\n",
    "            CC = 0\n",
    "            AB_exact = 0\n",
    "            CC_exact = 0\n",
    "            for sample in range(1100):\n",
    "                coalescence_time = expected_coalescence # np.random.exponential(expected_coalescence)\n",
    "                mut1 = rng.poisson(coalescence_time*0.00092*29903)\n",
    "                introduction_interval = expected_introduction # np.random.exponential(expected_introduction)\n",
    "                mut2 = rng.poisson((coalescence_time+introduction_interval)*0.00092*29903)\n",
    "                run_1, run_2 = rng.choice(range(1, 1101), 2, replace=True)\n",
    "                clade_sizes_1 = clade_analyses_CC_d[run_1]['clade_sizes'] # get the clade sizes\n",
    "                clade_sizes_2 = clade_analyses_CC_d[run_2]['clade_sizes'] # get the clade sizes\n",
    "                if len(clade_sizes_1) >= 100 and len(clade_sizes_2) >= 100:  # if there are at least X number of descendants, including individual leaves\n",
    "                    if test_sizes(run_1, run_2, introduction_interval):\n",
    "                        mut1 += root_mutations_d[run_1]\n",
    "                        mut2 += root_mutations_d[run_2]\n",
    "                        if 0 in [mut1,mut2] and (mut1>1 or mut2>1):\n",
    "                            AB += 1\n",
    "                            if (mut1 == 2 or mut2 == 2):\n",
    "                                AB_exact += 1\n",
    "                        elif mut1 > 0 and mut2 > 0:\n",
    "                            CC += 1\n",
    "                            if (mut1 == 1 and mut2 == 1):\n",
    "                                CC_exact += 1\n",
    "\n",
    "            CC_two_intros_v.append(CC/1100)\n",
    "            AB_two_intros_v.append(AB/1100)\n",
    "            CC_exact_two_intros_v.append(CC_exact/1100)\n",
    "            AB_exact_two_intros_v.append(AB_exact/1100)\n",
    "        CC_two_intros.append(CC_two_intros_v)\n",
    "        AB_two_intros.append(AB_two_intros_v)\n",
    "        CC_exact_two_intros.append(CC_exact_two_intros_v)\n",
    "        AB_exact_two_intros.append(AB_exact_two_intros_v)\n",
    " \n",
    "    cc_result = cc_count/1100\n",
    "    ab_result = ab_count/1100\n",
    "    cc_exact_result = cc_exact_count/1100\n",
    "    ab_exact_result = ab_exact_count/1100\n",
    "\n",
    "    return [CC_two_intros, AB_two_intros, cc_result, ab_result, CC_exact_two_intros, AB_exact_two_intros, cc_exact_result, ab_exact_result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_coalescence_range = [0, 1/365, 2/365, 4/365, 7/365, 14/365, 28/365]\n",
    "expected_introduction_range = [0, 1/365, 2/365, 4/365, 7/365, 14/365, 28/365]\n",
    "# collect clade analysis results\n",
    "def process_clade_analysis(i, seed):\n",
    "    clade_analyses_CC_dir = f'./resamples/{i}/clade_analyses_CC/'\n",
    "    clade_analyses_AB_dir = f'./resamples/{i}/clade_analyses_AB/'\n",
    "    clade_analyses_CC_exact_dir = f'./resamples/{i}/clade_analyses_CC_exact/'\n",
    "    clade_analyses_AB_exact_dir = f'./resamples/{i}/clade_analyses_AB_exact/'\n",
    "    root_mutations_dir = f'./resamples/{i}/'\n",
    "    return clade_analysis_updated(clade_analyses_CC_dir, clade_analyses_AB_dir, clade_analyses_CC_exact_dir, clade_analyses_AB_exact_dir, root_mutations_dir, '3.5 DT',expected_coalescence_range, expected_introduction_range, seed, min_polytomy_size=100)\n",
    "\n",
    "# Initialize lists to store results\n",
    "cc2 = []\n",
    "ab2 = []\n",
    "cc = []\n",
    "ab = []\n",
    "cc2_exact = []\n",
    "ab2_exact = []\n",
    "cc_exact = []\n",
    "ab_exact = []\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=24) as executor:\n",
    "    seeds = np.random.randint(0, 2**31, size=1000)\n",
    "    # Map process_clade_analysis function across the range of values\n",
    "    results = executor.map(process_clade_analysis, range(1000), seeds)\n",
    "\n",
    "    # Unpack the results and append them to the respective lists\n",
    "    for a, b, c, d, e, f, g, h in results:\n",
    "        cc2.append(a)\n",
    "        ab2.append(b)\n",
    "        cc.append(c)\n",
    "        ab.append(d)\n",
    "        cc2_exact.append(e)\n",
    "        ab2_exact.append(f)\n",
    "        cc_exact.append(g)\n",
    "        ab_exact.append(h)\n",
    "np.array(cc2)\n",
    "np.array(ab2)\n",
    "np.array(cc)\n",
    "np.array(ab)\n",
    "np.array(cc2_exact)\n",
    "np.array(ab2_exact)\n",
    "np.array(cc_exact)\n",
    "np.array(ab_exact)\n",
    "\n",
    "cc2 = np.mean(cc2, axis = 0)\n",
    "ab2 = np.mean(ab2, axis = 0)\n",
    "cc = np.mean(cc)\n",
    "ab = np.mean(ab)\n",
    "cc2_exact = np.mean(cc2_exact, axis = 0)\n",
    "ab2_exact = np.mean(ab2_exact, axis = 0)\n",
    "cc_exact = np.mean(cc_exact)\n",
    "ab_exact = np.mean(ab_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factors for combinations of\n",
      " - expected time between MRCA and first introduction (t1 days); and\n",
      " - expected time between introductions (t2 days).\n",
      "\n",
      "With the recCA rooting, and\n",
      "- the relaxed separation constraint (two or more mutations)\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.21\t0.22\t0.23\t0.24\t0.26\t0.25\t0.14\n",
      "1\t0.22\t0.23\t0.23\t0.25\t0.27\t0.26\t0.14\n",
      "2\t0.24\t0.25\t0.25\t0.26\t0.27\t0.25\t0.13\n",
      "4\t0.26\t0.27\t0.27\t0.28\t0.28\t0.26\t0.13\n",
      "7\t0.28\t0.29\t0.29\t0.29\t0.29\t0.25\t0.12\n",
      "14\t0.30\t0.29\t0.29\t0.29\t0.27\t0.22\t0.10\n",
      "28\t0.25\t0.24\t0.24\t0.23\t0.21\t0.17\t0.08\n",
      "\n",
      "- the strict separation constraint (exactly two mutations)\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.16\t0.17\t0.17\t0.18\t0.18\t0.15\t0.05\n",
      "1\t0.17\t0.17\t0.17\t0.18\t0.18\t0.15\t0.05\n",
      "2\t0.18\t0.18\t0.18\t0.18\t0.18\t0.14\t0.04\n",
      "4\t0.19\t0.18\t0.18\t0.18\t0.17\t0.13\t0.04\n",
      "7\t0.18\t0.18\t0.18\t0.17\t0.16\t0.11\t0.03\n",
      "14\t0.14\t0.14\t0.13\t0.12\t0.10\t0.07\t0.02\n",
      "28\t0.05\t0.04\t0.04\t0.04\t0.03\t0.02\t0.00\n",
      "\n",
      "With the unconstrained rooting, and\n",
      "- the relaxed separation constraint (two or more mutations)\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.21\t0.21\t0.22\t0.23\t0.25\t0.24\t0.13\n",
      "1\t0.22\t0.22\t0.23\t0.24\t0.26\t0.24\t0.13\n",
      "2\t0.23\t0.24\t0.24\t0.25\t0.26\t0.24\t0.12\n",
      "4\t0.25\t0.25\t0.26\t0.26\t0.26\t0.24\t0.12\n",
      "7\t0.27\t0.27\t0.28\t0.28\t0.27\t0.23\t0.11\n",
      "14\t0.28\t0.27\t0.27\t0.27\t0.25\t0.21\t0.09\n",
      "28\t0.22\t0.22\t0.21\t0.21\t0.19\t0.15\t0.07\n",
      "\n",
      "- the strict separation constraint (exactly two mutations)\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.16\t0.16\t0.17\t0.17\t0.18\t0.15\t0.05\n",
      "1\t0.17\t0.17\t0.17\t0.17\t0.18\t0.15\t0.05\n",
      "2\t0.18\t0.18\t0.18\t0.18\t0.18\t0.14\t0.04\n",
      "4\t0.18\t0.18\t0.18\t0.18\t0.17\t0.13\t0.03\n",
      "7\t0.17\t0.18\t0.17\t0.17\t0.15\t0.11\t0.03\n",
      "14\t0.13\t0.13\t0.13\t0.12\t0.10\t0.06\t0.02\n",
      "28\t0.05\t0.04\t0.04\t0.04\t0.03\t0.02\t0.00\n"
     ]
    }
   ],
   "source": [
    "# Setup the MRCA haplotype posterior probabilities for the Bayes factor calculation\n",
    "unconstrained_results = np.array([1.68, 80.85, 10.32, 0.92])/100  \n",
    "recCA_results = np.array([77.28, 8.18, 10.49, 3.71])/100  \n",
    "\n",
    "print('Bayes factors for combinations of')\n",
    "print(' - expected time between MRCA and first introduction (t1 days); and')\n",
    "print(' - expected time between introductions (t2 days).\\n')\n",
    "print('With the recCA rooting, and')\n",
    "print('- the relaxed separation constraint (two or more mutations)')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        bf.append((sum(recCA_results[:2])*ab2[i][j] + sum(recCA_results[2:])*cc2[i][j]) / \\\n",
    "        (sum(recCA_results[:2])*ab + sum(recCA_results[2:])*cc))\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x:.2f}' for x in bf]))\n",
    "print('\\n- the strict separation constraint (exactly two mutations)')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        bf.append((sum(recCA_results[:2])*ab2_exact[i][j] + sum(recCA_results[2:])*cc2_exact[i][j]) / \\\n",
    "        (sum(recCA_results[:2])*ab_exact + sum(recCA_results[2:])*cc_exact))\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x:.2f}' for x in bf]))\n",
    "print('\\nWith the unconstrained rooting, and')\n",
    "print('- the relaxed separation constraint (two or more mutations)')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        bf.append((sum(unconstrained_results[:2])*ab2[i][j] + sum(unconstrained_results[2:])*cc2[i][j]) / \\\n",
    "        (sum(unconstrained_results[:2])*ab + sum(unconstrained_results[2:])*cc))\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x:.2f}' for x in bf]))\n",
    "print('\\n- the strict separation constraint (exactly two mutations)')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        bf.append((sum(unconstrained_results[:2])*ab2_exact[i][j] + sum(unconstrained_results[2:])*cc2_exact[i][j]) / \\\n",
    "        (sum(unconstrained_results[:2])*ab_exact + sum(unconstrained_results[2:])*cc_exact))\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x:.2f}' for x in bf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### recCA - relaxed\n",
      "|  |$t_2$ = 0 days | $t_2$ = 1 days | $t_2$ = 2 days | $t_2$ = 4 days | $t_2$ = 7 days | $t_2$ = 14 days | $t_2$ = 28 days |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| $t_1$ **= 0 days** |0.21 | 0.22 | 0.23 | 0.24 | 0.26 | 0.25 | 0.14 |\n",
      "| $t_1$ **= 1 days** |0.22 | 0.23 | 0.23 | 0.25 | 0.27 | 0.26 | 0.14 |\n",
      "| $t_1$ **= 2 days** |0.24 | 0.25 | 0.25 | 0.26 | 0.27 | 0.25 | 0.13 |\n",
      "| $t_1$ **= 4 days** |0.26 | 0.27 | 0.27 | 0.28 | 0.28 | 0.26 | 0.13 |\n",
      "| $t_1$ **= 7 days** |0.28 | 0.29 | 0.29 | 0.29 | 0.29 | 0.25 | 0.12 |\n",
      "| $t_1$ **= 14 days** |0.30 | 0.29 | 0.29 | 0.29 | 0.27 | 0.22 | 0.10 |\n",
      "| $t_1$ **= 28 days** |0.25 | 0.24 | 0.24 | 0.23 | 0.21 | 0.17 | 0.08 |\n",
      "### unconstrained - relaxed\n",
      "|  |$t_2$ = 0 days | $t_2$ = 1 days | $t_2$ = 2 days | $t_2$ = 4 days | $t_2$ = 7 days | $t_2$ = 14 days | $t_2$ = 28 days |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| $t_1$ **= 0 days** |0.21 | 0.21 | 0.22 | 0.23 | 0.25 | 0.24 | 0.13 |\n",
      "| $t_1$ **= 1 days** |0.22 | 0.22 | 0.23 | 0.24 | 0.26 | 0.24 | 0.13 |\n",
      "| $t_1$ **= 2 days** |0.23 | 0.24 | 0.24 | 0.25 | 0.26 | 0.24 | 0.12 |\n",
      "| $t_1$ **= 4 days** |0.25 | 0.25 | 0.26 | 0.26 | 0.26 | 0.24 | 0.12 |\n",
      "| $t_1$ **= 7 days** |0.27 | 0.27 | 0.28 | 0.28 | 0.27 | 0.23 | 0.11 |\n",
      "| $t_1$ **= 14 days** |0.28 | 0.27 | 0.27 | 0.27 | 0.25 | 0.21 | 0.09 |\n",
      "| $t_1$ **= 28 days** |0.22 | 0.22 | 0.21 | 0.21 | 0.19 | 0.15 | 0.07 |\n",
      "### recCA - strict\n",
      "|  |$t_2$ = 0 days | $t_2$ = 1 days | $t_2$ = 2 days | $t_2$ = 4 days | $t_2$ = 7 days | $t_2$ = 14 days | $t_2$ = 28 days |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| $t_1$ **= 0 days** |0.16 | 0.17 | 0.17 | 0.18 | 0.18 | 0.15 | 0.05 |\n",
      "| $t_1$ **= 1 days** |0.17 | 0.17 | 0.17 | 0.18 | 0.18 | 0.15 | 0.05 |\n",
      "| $t_1$ **= 2 days** |0.18 | 0.18 | 0.18 | 0.18 | 0.18 | 0.14 | 0.04 |\n",
      "| $t_1$ **= 4 days** |0.19 | 0.18 | 0.18 | 0.18 | 0.17 | 0.13 | 0.04 |\n",
      "| $t_1$ **= 7 days** |0.18 | 0.18 | 0.18 | 0.17 | 0.16 | 0.11 | 0.03 |\n",
      "| $t_1$ **= 14 days** |0.14 | 0.14 | 0.13 | 0.12 | 0.10 | 0.07 | 0.02 |\n",
      "| $t_1$ **= 28 days** |0.05 | 0.04 | 0.04 | 0.04 | 0.03 | 0.02 | 0.00 |\n",
      "### unconstrained - strict\n",
      "|  |$t_2$ = 0 days | $t_2$ = 1 days | $t_2$ = 2 days | $t_2$ = 4 days | $t_2$ = 7 days | $t_2$ = 14 days | $t_2$ = 28 days |\n",
      "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
      "| $t_1$ **= 0 days** |0.16 | 0.16 | 0.17 | 0.17 | 0.18 | 0.15 | 0.05 |\n",
      "| $t_1$ **= 1 days** |0.17 | 0.17 | 0.17 | 0.17 | 0.18 | 0.15 | 0.05 |\n",
      "| $t_1$ **= 2 days** |0.18 | 0.18 | 0.18 | 0.18 | 0.18 | 0.14 | 0.04 |\n",
      "| $t_1$ **= 4 days** |0.18 | 0.18 | 0.18 | 0.18 | 0.17 | 0.13 | 0.03 |\n",
      "| $t_1$ **= 7 days** |0.17 | 0.18 | 0.17 | 0.17 | 0.15 | 0.11 | 0.03 |\n",
      "| $t_1$ **= 14 days** |0.13 | 0.13 | 0.13 | 0.12 | 0.10 | 0.06 | 0.02 |\n",
      "| $t_1$ **= 28 days** |0.05 | 0.04 | 0.04 | 0.04 | 0.03 | 0.02 | 0.00 |\n"
     ]
    }
   ],
   "source": [
    "print('### recCA - relaxed')\n",
    "# Header\n",
    "print('|  |', end='')\n",
    "print(' | '.join(f'$t_2$ = {int(x*365)} days' for x in expected_introduction_range), '|')\n",
    "print('|---|' + '|'.join([':---:' for _ in expected_introduction_range]) + '|')\n",
    "\n",
    "# Rows\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        numerator = sum(recCA_results[:2]) * ab2[i][j] + sum(recCA_results[2:]) * cc2[i][j]\n",
    "        denominator = sum(recCA_results[:2]) * ab + sum(recCA_results[2:]) * cc\n",
    "        bf.append(numerator / denominator)\n",
    "    # Row print with formatting\n",
    "    print(f'| $t_1$ **= {int(expected_coalescence_range[i]*365)} days** |', end='')\n",
    "    print(' | '.join(f'{x:.2f}' for x in bf), '|')\n",
    "print('### unconstrained - relaxed')\n",
    "# Header\n",
    "print('|  |', end='')\n",
    "print(' | '.join(f'$t_2$ = {int(x*365)} days' for x in expected_introduction_range), '|')\n",
    "print('|---|' + '|'.join([':---:' for _ in expected_introduction_range]) + '|')\n",
    "\n",
    "# Rows\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        numerator = sum(unconstrained_results[:2]) * ab2[i][j] + sum(unconstrained_results[2:]) * cc2[i][j]\n",
    "        denominator = sum(unconstrained_results[:2]) * ab + sum(unconstrained_results[2:]) * cc\n",
    "        bf.append(numerator / denominator)\n",
    "    # Row print with formatting\n",
    "    print(f'| $t_1$ **= {int(expected_coalescence_range[i]*365)} days** |', end='')\n",
    "    print(' | '.join(f'{x:.2f}' for x in bf), '|')\n",
    "print('### recCA - strict')\n",
    "# Header\n",
    "print('|  |', end='')\n",
    "print(' | '.join(f'$t_2$ = {int(x*365)} days' for x in expected_introduction_range), '|')\n",
    "print('|---|' + '|'.join([':---:' for _ in expected_introduction_range]) + '|')\n",
    "\n",
    "# Rows\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        numerator = sum(recCA_results[:2]) * ab2_exact[i][j] + sum(recCA_results[2:]) * cc2_exact[i][j]\n",
    "        denominator = sum(recCA_results[:2]) * ab_exact + sum(recCA_results[2:]) * cc_exact\n",
    "        bf.append(numerator / denominator)\n",
    "    # Row print with formatting\n",
    "    print(f'| $t_1$ **= {int(expected_coalescence_range[i]*365)} days** |', end='')\n",
    "    print(' | '.join(f'{x:.2f}' for x in bf), '|')\n",
    "print('### unconstrained - strict')\n",
    "# Header\n",
    "print('|  |', end='')\n",
    "print(' | '.join(f'$t_2$ = {int(x*365)} days' for x in expected_introduction_range), '|')\n",
    "print('|---|' + '|'.join([':---:' for _ in expected_introduction_range]) + '|')\n",
    "\n",
    "# Rows\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    bf = []\n",
    "    for j in range(len(expected_introduction_range)):\n",
    "        numerator = sum(unconstrained_results[:2]) * ab2_exact[i][j] + sum(unconstrained_results[2:]) * cc2_exact[i][j]\n",
    "        denominator = sum(unconstrained_results[:2]) * ab_exact + sum(unconstrained_results[2:]) * cc_exact\n",
    "        bf.append(numerator / denominator)\n",
    "    # Row print with formatting\n",
    "    print(f'| $t_1$ **= {int(expected_coalescence_range[i]*365)} days** |', end='')\n",
    "    print(' | '.join(f'{x:.2f}' for x in bf), '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mutation(s): 50.5%\n",
      "1 mutation(s): 26.0%\n",
      "2 mutation(s): 12.4%\n",
      "3 mutation(s): 11.0%\n"
     ]
    }
   ],
   "source": [
    "mutation_counts = [0,0,0,0]\n",
    "for i in range(1000):\n",
    "    for j in range(1,1101):\n",
    "        path = f'resamples/{i}/{j:04d}_root_mutations.txt'\n",
    "        with open(path) as file:\n",
    "            n = int(file.readline().strip())\n",
    "        if n > 3:\n",
    "            n = 3\n",
    "        mutation_counts[n] += 1\n",
    "for muts, n in enumerate(mutation_counts):\n",
    "    print(f'{muts} mutation(s): {n/1000/11:.1f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB topology frequencies\n",
      "\n",
      "With the relaxed separation constraint (two or more mutations)\n",
      "Single introduction frequency: 3.3%\n",
      "Two introduction frequencies:\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.6%\t0.6%\t0.6%\t0.6%\t0.7%\t0.7%\t0.3%\n",
      "1\t0.6%\t0.6%\t0.6%\t0.7%\t0.7%\t0.6%\t0.3%\n",
      "2\t0.6%\t0.7%\t0.7%\t0.7%\t0.7%\t0.6%\t0.3%\n",
      "4\t0.7%\t0.7%\t0.7%\t0.7%\t0.7%\t0.6%\t0.3%\n",
      "7\t0.7%\t0.7%\t0.7%\t0.7%\t0.7%\t0.5%\t0.2%\n",
      "14\t0.6%\t0.6%\t0.6%\t0.6%\t0.5%\t0.4%\t0.1%\n",
      "28\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.2%\t0.1%\n",
      "\n",
      "With the strict separation constraint (exactly two mutations)\n",
      "Single introduction frequency: 2.5%\n",
      "Two introduction frequencies:\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.4%\t0.4%\t0.4%\t0.4%\t0.4%\t0.4%\t0.1%\n",
      "1\t0.4%\t0.4%\t0.4%\t0.4%\t0.4%\t0.3%\t0.1%\n",
      "2\t0.4%\t0.4%\t0.4%\t0.4%\t0.4%\t0.3%\t0.1%\n",
      "4\t0.4%\t0.4%\t0.4%\t0.4%\t0.4%\t0.3%\t0.1%\n",
      "7\t0.4%\t0.4%\t0.4%\t0.4%\t0.3%\t0.2%\t0.1%\n",
      "14\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.1%\t0.0%\n",
      "28\t0.1%\t0.1%\t0.1%\t0.1%\t0.1%\t0.0%\t0.0%\n"
     ]
    }
   ],
   "source": [
    "print('AB topology frequencies')\n",
    "print('')\n",
    "print('With the relaxed separation constraint (two or more mutations)')\n",
    "print(f'Single introduction frequency: {ab*100:.1f}%')\n",
    "print('Two introduction frequencies:')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x*100:.1f}%' for x in ab2[i]]))\n",
    "print('\\nWith the strict separation constraint (exactly two mutations)')\n",
    "print(f'Single introduction frequency: {ab_exact*100:.1f}%')\n",
    "print('Two introduction frequencies:')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x*100:.1f}%' for x in ab2_exact[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC topology frequencies\n",
      "\n",
      "With the relaxed separation constraint (two or more mutations)\n",
      "Single introduction frequency: 0.2%\n",
      "Two introduction frequencies:\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.7%\t0.8%\t0.9%\t1.0%\t1.1%\t1.2%\t0.9%\n",
      "1\t0.9%\t1.0%\t1.0%\t1.1%\t1.2%\t1.3%\t0.9%\n",
      "2\t1.0%\t1.0%\t1.1%\t1.2%\t1.3%\t1.3%\t0.9%\n",
      "4\t1.2%\t1.3%\t1.3%\t1.4%\t1.5%\t1.5%\t1.0%\n",
      "7\t1.6%\t1.6%\t1.6%\t1.7%\t1.8%\t1.7%\t1.0%\n",
      "14\t2.2%\t2.2%\t2.3%\t2.3%\t2.3%\t2.1%\t1.1%\n",
      "28\t2.9%\t2.9%\t2.9%\t2.9%\t2.9%\t2.4%\t1.3%\n",
      "\n",
      "With the strict separation constraint (exactly two mutations)\n",
      "Single introduction frequency: 0.1%\n",
      "Two introduction frequencies:\n",
      "\tt2\n",
      "t1\t0\t1\t2\t4\t7\t14\t28\n",
      "0\t0.2%\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.1%\n",
      "1\t0.3%\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.1%\n",
      "2\t0.3%\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.1%\n",
      "4\t0.3%\t0.3%\t0.4%\t0.3%\t0.3%\t0.2%\t0.1%\n",
      "7\t0.4%\t0.4%\t0.4%\t0.3%\t0.3%\t0.2%\t0.0%\n",
      "14\t0.3%\t0.3%\t0.3%\t0.3%\t0.2%\t0.1%\t0.0%\n",
      "28\t0.1%\t0.1%\t0.1%\t0.1%\t0.1%\t0.0%\t0.0%\n"
     ]
    }
   ],
   "source": [
    "print('CC topology frequencies')\n",
    "print('')\n",
    "print('With the relaxed separation constraint (two or more mutations)')\n",
    "print(f'Single introduction frequency: {cc*100:.1f}%')\n",
    "print('Two introduction frequencies:')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x*100:.1f}%' for x in cc2[i]]))\n",
    "print('\\nWith the strict separation constraint (exactly two mutations)')\n",
    "print(f'Single introduction frequency: {cc_exact*100:.1f}%')\n",
    "print('Two introduction frequencies:')\n",
    "print('\\tt2')\n",
    "print('t1\\t' + '\\t'.join([str(int(x*365)) for x in expected_introduction_range]))\n",
    "for i in range(len(expected_coalescence_range)):\n",
    "    print(f'{int(expected_coalescence_range[i]*365):d}\\t' + '\\t'.join([f'{x*100:.1f}%' for x in cc2_exact[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
